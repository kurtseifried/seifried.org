<!doctype html>
<html amp lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1,maximum-scale=1,user-scalable=no">
 
<meta property="og:type" content="article"/>
<meta property="og:title" content="Python Performance Part 1"/>
<meta property="og:url" content="http://kurt.seifried.org/2010/05/31/python-performance-part-1/"/>
<meta property="og:description" content="Python Performance Part 2 Python Performance Part 3 Python Performance Part 4 If you&#8217;ve been programming in Python chances are you have run into a situation where your code takes a lot longer…"/>
<meta property="article:published_time" content="2010-05-31T08:24:46+00:00"/>
<meta property="article:modified_time" content="2010-05-31T19:21:20+00:00"/>
<meta property="og:site_name" content="Kurt Seifried"/>
<meta property="og:image" content="https://s0.wp.com/i/blank.jpg"/>
<meta property="og:locale" content="en_US"/>
<meta name="twitter:site" content="@wordpressdotcom"/>
<meta name="twitter:card" content="summary"/>
<meta property="article:publisher" content="https://www.facebook.com/WordPresscom"/>
<title>Python Performance Part 1 &#8211; Kurt Seifried</title>
<link rel="canonical" href="http://kurt.seifried.org/2010/05/31/python-performance-part-1/"/>
<script src="https://cdn.ampproject.org/v0.js" async></script>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Merriweather:400,400italic,700,700italic">
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
<script type="application/ld+json">{"@context":"http:\/\/schema.org","@type":"BlogPosting","mainEntityOfPage":"http:\/\/kurt.seifried.org\/2010\/05\/31\/python-performance-part-1\/","publisher":{"@type":"Organization","name":"Kurt Seifried","logo":{"@type":"ImageObject","url":"https:\/\/s2.wp.com\/i\/favicons\/apple-touch-icon-60x60.png","width":60,"height":60}},"headline":"Python Performance Part 1","datePublished":"2010-05-31T02:24:46+00:00","dateModified":"2010-05-31T13:21:20+00:00","author":{"@type":"Person","name":"kurtseifried"},"image":{"@type":"ImageObject","url":"http:\/\/2.gravatar.com\/avatar\/8b588344181b6098f508e9741ac36e0e?s=200&amp;d=identicon&amp;r=G","width":200,"height":200}}</script>
<style amp-custom>.alignright{float:right;}.alignleft{float:left;}.aligncenter{display:block;margin-left:auto;margin-right:auto;}.amp-wp-enforced-sizes{max-width:100%;margin:0 auto;}.amp-wp-unknown-size img{object-fit:contain;}.amp-wp-content,.amp-wp-title-bar div{margin:0 auto;max-width:450px;}html{background:#0a89c0;}body{background:#fff;color:#353535;font-family:'Merriweather','Times New Roman',Times,Serif;font-weight:300;line-height:1.75em;}p,ol,ul,figure{margin:0 0 1em;padding:0;}a,a:visited{color:#0a89c0;}a:hover,a:active,a:focus{color:#353535;}blockquote{color:#353535;background:rgba(127,127,127,.125);border-left:2px solid #0a89c0;margin:8px 0 24px 0;padding:16px;}blockquote p:last-child{margin-bottom:0;}.amp-wp-meta,.amp-wp-header div,.amp-wp-title,.wp-caption-text,.amp-wp-tax-category,.amp-wp-tax-tag,.amp-wp-comments-link,.amp-wp-footer p,.back-to-top{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI","Roboto","Oxygen-Sans","Ubuntu","Cantarell","Helvetica Neue",sans-serif;}.amp-wp-header{background-color:#0a89c0;}.amp-wp-header div{color:#fff;font-size:1em;font-weight:400;margin:0 auto;max-width:calc(840px - 32px);padding:.875em 16px;position:relative;}.amp-wp-header a{color:#fff;text-decoration:none;}.amp-wp-header .amp-wp-site-icon{background-color:#fff;border:1px solid #fff;border-radius:50%;position:absolute;right:18px;top:10px;}.amp-wp-article{color:#353535;font-weight:400;margin:1.5em auto;max-width:840px;overflow-wrap:break-word;word-wrap:break-word;}.amp-wp-article-header{align-items:center;align-content:stretch;display:flex;flex-wrap:wrap;justify-content:space-between;margin:1.5em 16px 1.5em;}.amp-wp-title{color:#353535;display:block;flex:1 0 100%;font-weight:900;margin:0 0 .625em;width:100%;}.amp-wp-meta{color:#696969;display:inline-block;flex:2 1 50%;font-size:.875em;line-height:1.5em;margin:0;padding:0;}.amp-wp-article-header .amp-wp-meta:last-of-type{text-align:right;}.amp-wp-article-header .amp-wp-meta:first-of-type{text-align:left;}.amp-wp-byline amp-img,.amp-wp-byline .amp-wp-author{display:inline-block;vertical-align:middle;}.amp-wp-byline amp-img{border:1px solid #0a89c0;border-radius:50%;position:relative;margin-right:6px;}.amp-wp-posted-on{text-align:right;}.amp-wp-article-featured-image{margin:0 0 1em;}.amp-wp-article-featured-image amp-img{margin:0 auto;}.amp-wp-article-featured-image.wp-caption .wp-caption-text{margin:0 18px;}.amp-wp-article-content{margin:0 16px;}.amp-wp-article-content ul,.amp-wp-article-content ol{margin-left:1em;}.amp-wp-article-content amp-img{margin:0 auto;}.amp-wp-article-content amp-img.alignright{margin:0 0 1em 16px;}.amp-wp-article-content amp-img.alignleft{margin:0 16px 1em 0;}.wp-caption{padding:0;}.wp-caption.alignleft{margin-right:16px;}.wp-caption.alignright{margin-left:16px;}.wp-caption .wp-caption-text{border-bottom:1px solid #c2c2c2;color:#696969;font-size:.875em;line-height:1.5em;margin:0;padding:.66em 10px .75em;}amp-carousel{background:#c2c2c2;margin:0 -16px 1.5em;}amp-iframe,amp-youtube,amp-instagram,amp-vine{background:#c2c2c2;margin:0 -16px 1.5em;}.amp-wp-article-content amp-carousel amp-img{border:none;}amp-carousel>amp-img>img{object-fit:contain;}.amp-wp-iframe-placeholder{background:#c2c2c2 url(http://s2.wp.com/wp-content/plugins/amp/assets/images/placeholder-icon.png) no-repeat center 40%;background-size:48px 48px;min-height:48px;}.amp-wp-article-footer .amp-wp-meta{display:block;}.amp-wp-tax-category,.amp-wp-tax-tag{color:#696969;font-size:.875em;line-height:1.5em;margin:1.5em 16px;}.amp-wp-comments-link{color:#696969;font-size:.875em;line-height:1.5em;text-align:center;margin:2.25em 0 1.5em;}.amp-wp-comments-link a{border-style:solid;border-color:#c2c2c2;border-width:1px 1px 2px;border-radius:4px;background-color:transparent;color:#0a89c0;cursor:pointer;display:block;font-size:14px;font-weight:600;line-height:18px;margin:0 auto;max-width:200px;padding:11px 16px;text-decoration:none;width:50%;-webkit-transition:background-color 0.2s ease;transition:background-color 0.2s ease;}.amp-wp-footer{border-top:1px solid #c2c2c2;margin:calc(1.5em - 1px) 0 0;}.amp-wp-footer div{margin:0 auto;max-width:calc(840px - 32px);padding:1.25em 16px 1.25em;position:relative;}.amp-wp-footer h2{font-size:1em;line-height:1.375em;margin:0 0 .5em;}.amp-wp-footer p{color:#696969;font-size:.8em;line-height:1.5em;margin:0 85px 0 0;}.amp-wp-footer a{text-decoration:none;}.back-to-top{bottom:1.275em;font-size:.8em;font-weight:600;line-height:2em;position:absolute;right:16px;}.amp-wp-inline-2d119d10fc2234fa6e8a2b1b22ff1050{height:1px;left:-10000px;overflow:hidden;position:absolute;top:532px;max-width:1px;}.amp-wp-inline-5bb1f0538cda713ea03612369398c0e8{font-family:&amp;font-size:12pt;}.amp-wp-inline-61cd676b7bd65a074cc1d867fbbea1de{text-decoration:underline;}</style>
</head>
<body class="">
<header id="#top" class="amp-wp-header">
<div>
<a href="http://kurt.seifried.org">
Kurt Seifried </a>
</div>
</header>
<article class="amp-wp-article">
<header class="amp-wp-article-header">
<h1 class="amp-wp-title">Python Performance Part 1</h1>
<div class="amp-wp-meta amp-wp-byline">
<amp-img src="http://2.gravatar.com/avatar/8b588344181b6098f508e9741ac36e0e?s=24&#038;d=identicon&#038;r=g" width="24" height="24" layout="fixed"></amp-img>
<span class="amp-wp-author author vcard">kurtseifried</span>
</div>
<div class="amp-wp-meta amp-wp-posted-on">
<time datetime="2010-05-31T02:24:46+00:00">
7 years ago </time>
</div>
</header>
<div class="amp-wp-article-content">
<p><a href="http://kurt.seifried.org/2010/05/31/python-performance-part-2/">Python Performance Part 2</a><br/><a href="http://kurt.seifried.org/2010/05/31/python-performance-part-3/">Python Performance Part 3</a><br/><a href="http://kurt.seifried.org/2010/05/31/python-performance-part-4/">Python Performance Part 4</a></p>
<p>If you’ve been programming in Python chances are you have run into a situation where your code takes a lot longer to run than it probably should, and if you haven’t used Python I’m going to show you how easy it ease to write high performance and scalable code that will run fast.</p>
<p>These articles do not cover why you should use Python (it’s cool, it ships standard on every Linux distribution, all the kids at Google use it, etc.). These articles will specifically cover how you can speed up Python performance (parallelization, code profiling, performance measuring, etc.) and include code examples (for brevity I will use pseudo code for some of the longer examples). I will also cover some Python internals so that you will understand why speeding up code doesn’t always work as expected (and what you can do about this). Please note that older versions of Python (e.g. 2.4.3 as shipped with Red Hat Enterprise and CentOS) do not support some of the things discussed in these articles. The reference platform used for this article is Fedora 12 (Python 2.6.4, Beanstalkd 1.4.2, memcached 1.4.4 and MySQL 5.1.41 basically).</p>
<p><strong>A (super) quick introduction to Python threading</strong></p>
<p>You have two basic modules that provide threading capabilities in Python. The first (and oldest) module is “thread” [THREAD] which provides low-level primitives such as creating a thread, exiting and some lock primitives so you can use shared resources safely. You don’t want to use this module for reasons I will shortly explain. The second module is “threading” [THREADING] and it builds upon the low level primitives (similar to SocketServer, HTTPServer, etc.) provided by “thread”. In Python the main program runs as a single thread, from this thread you can create additional child threads (these run within the same process space and thus have shared memory). The main trick is that you need the main thread to keep running while the children threads are doing their thing, if the main thread exits than all the child threads get killed off unceremoniously, potentially leaving a mess. This is why you don’t want to use “thread”, as you will need to create your own spinlock to hold the main thread open while the children threads run. With the “threading” module the system provides the join() method which “blocks the calling thread until the thread whose join() method is called is terminated.”</p>
<p>It should be noted that in many cases the main thread will continue running until threads started using the threading Thread.start() are done but there are no guarantees so I strongly suggest you use the join() method or create your own spinlock (especially if using older versions of Python).</p>
<p><strong>Basic Threading Pattern</strong></p>
<p>The basic threading pattern in Python (and most languages) is to take a bunch of work and split it up among different threads (insightful, yes?). The idea is that instead of doing things sequentially (one at a time) you do them in parallel (more than one at a time). For many tasks this works well, especially if the tasks are largely bound by IO (Input and Output) delays (especially for network related stuff).</p>
<table border="1" cellspacing="0" cellpadding="7" width="680"><col width="404"/><col width="245"/><tbody><tr><td width="404">web_get_parallel.py – (no join())</td>
<td width="245">Comment</td>
</tr><tr><td width="404"><!--[if gte mso 9]&gt;  Normal 0   false false false        MicrosoftInternetExplorer4  &lt;![endif]--><!--[if gte mso 9]&gt;   &lt;![endif]-->
<pre>#!/usr/bin/env python&#13;
import urllib2&#13;
from threading import Thread&#13;
hosts = ["http://lwn.net/", "http://seifried.org/", "http://google.com/"]&#13;
&#13;
def getURL(URL):&#13;
    urllib2.urlopen(URL)&#13;
    print "got URL: " + URL&#13;
&#13;
for item in hosts:&#13;
    t = Thread(target=getURL, args=(item,))&#13;
    t.start()&#13;
</pre>
</td>
<td width="245"># list of web pages to get# define a get URL function# loop through the list of URLs# define a thread
<p># start the thread</p></td>
</tr></tbody></table><p>But is this really faster than doing the work sequentially?</p>
<table border="1" cellspacing="0" cellpadding="7" width="680"><col width="404"/><col width="245"/><tbody><tr><td width="404">web_get_sequential.py</td>
<td width="245">Comment</td>
</tr><tr><td width="404"><!--[if gte mso 9]&gt;  Normal 0   false false false        MicrosoftInternetExplorer4  &lt;![endif]--><!--[if gte mso 9]&gt;   &lt;![endif]-->
<pre>#!/usr/bin/env python&#13;
import urllib2&#13;
hosts = ["http://lwn.net/", "http://seifried.org/", "http://google.com/"]&#13;
&#13;
def getURL(URL):&#13;
    urllib2.urlopen(URL)&#13;
    print "got URL: " + URL&#13;
&#13;
for item in hosts:&#13;
    urllib2.urlopen(item)&#13;
    print "got URL: " + URL&#13;
</pre>
</td>
<td width="245"># list of web pages to get# define a get URL function# loop through the list of URLs# get the URL</td>
</tr></tbody></table><p>So based on this the parallel threaded example (not using join()) takes about a 0.5 seconds according to the UNIX “time” command, and the sequential version takes 6 seconds. This is obviously not right, assuming the sequential one takes about the same amount of time to get each URL (best case) then the parallel version should take 2 seconds (6/3 = 2).</p>
<p>So why is it only taking 0.5 seconds? Probably because the main thread exited before the children are done running (which means we didn’t finish our work). So let’s fix that:</p>
<table border="1" cellspacing="0" cellpadding="7" width="680"><col width="404"/><col width="245"/><tbody><tr><td width="404">web_get_parallel.py (with join())</td>
<td width="245">Comment</td>
</tr><tr><td width="404">
<pre>#!/usr/bin/env python&#13;
import urllib2&#13;
from threading import Thread&#13;
thread_list = []&#13;
hosts = ["http://lwn.net/", "http://seifried.org/", "http://google.com/"]&#13;
&#13;
def getURL(URL):&#13;
    urllib2.urlopen(URL)&#13;
    print "got URL: " + URL&#13;
&#13;
for item in hosts:&#13;
    t = Thread(target=getURL, args=(item,))&#13;
    t.start()&#13;
    thread_list.append(t)&#13;
&#13;
for thread in thread_list:&#13;
    thread.join()&#13;
</pre>
</td>
<td width="245"># list of web pages to get# define a get URL function# loop through the list of URLs# define a thread
<p># start the thread</p>
<p># loop through the list of threads</p>
<p># join each thread</p></td>
</tr></tbody></table><p>Great, the code now takes about 2.5 seconds, and we are actually getting the web pages correctly! As you can see this is a significant speed, taking only as long as the slowest web page (probably my site), and the sequential example taking the time it takes to get all the pages in total (we’ll cover how to measure performance properly later in this series).</p>
<p><strong>Why Threading Helps Performance</strong></p>
<p>The reason that we get such a significant speed up in this case is that the program is spending the majority of its time waiting for the remote web servers to respond with web pages that it has requested and about 1% (in other words not very much) of the time is spent creating and sending those requests. When a python thread does something IO related (reading or writing a file, sending a network request, waiting for a response, etc.) it essentially goes to sleep, at which point a different thread is given a chance to execute (so instead of simply waiting around the program can do other work as well). Additionally because threads share memory space the program won’t use much more memory (whereas if you split the work between different processes each one would have it’s own memory leading to much duplication). A final advantage of memory sharing is that variables and objects can be accessed by multiple threads; there is no need to engineer inter-process communications (although with the multiprocessing module this is trivial, more on this later in the fourth article of this series).</p>
<p>But what happens if we have a much larger workload (instead of 3 domains to get we have 3 million) and a much more complex workload (we have to get the web pages, extract data from them and process the data for example). If we try to start up 3 million threads to handle each domain individually I can pretty much guarantee you are not going to increase performance.</p>
<p><strong>Advanced Threading pattern</strong></p>
<p>So starting up one thread per task is probably not the most optimal way to go, especially if the workload is large or if it varies. But how can we efficiently divvy up the workload among a (possibly indeterminate) number of threads? Taking the total number of things to do and dividing by the number of threads and then assigning that many things to each thread is not optimal. What if one thread gets saddled with URL’s that all take much longer than average to download? We are then left with one thread still running while the rest are finished their work and waiting idly. Also the amount of work may not be known in advance, or we want to be able to add more work. We may be reading URL’s from a database or a file and not know in advance how many we have.</p>
<p>This is where Python work queues come in [WORKQUEUE]. A work queue provides a way to handle and share multiple objects, you put items into a queue and then retrieve them, the queue ensures that objects are entered correctly and removed correctly (so with multiple threads accessing a queue you don’t need to worry about locking and so on, you simply write to the queue or read from it and it works). Queues in Python can be FIFO (first in, first out, think of a pipe), LIFO (last in first out, think of a stack) and priority based (you can assign priorities to objects and then make sure that higher priority items are processed before lower priority items and so on).</p>
<p>Queue syntax is very simple: you create a queue, then you put objects into it and get objects out of it. This allows you to use the producer/consumer pattern [Producer-consumer problem]. The following example has a producer thread that reads the URL entries into a queue, and a group of worker threads that pull an item from the queue, process it and then repeat until the queue is empty at which time they exit. In order to ensure that the main thread runs for a long enough time to let the producer and consumer child threads finish their work we’ll simply use the thread.join() method to hold the main thread open until all the children have exited.</p>
<table border="1" cellspacing="0" cellpadding="4" width="665"><col width="435"/><col width="212"/><tbody><tr><td width="435">web_get_producer_consumer_basic_pattern.py</td>
<td width="212"></td>
</tr><tr><td width="435">
<pre>#!/usr/bin/env python&#13;
&#13;
import urllib2&#13;
import sys&#13;
import Queue&#13;
from threading import Thread&#13;
&#13;
host_list = ["http://lwn.net/", "http://seifried.org/", "http://google.com/", "http://yahoo.com/", "http://gmail.com/"]&#13;
&#13;
thread_list = []&#13;
URL_work_queue = Queue.Queue()&#13;
number_of_consumer_threads = 3&#13;
&#13;
def putURL(URL_list):&#13;
    for URL_item in URL_list:&#13;
        URL_work_queue.put(URL_item)&#13;
&#13;
def getURL(thread_id):&#13;
    while 1:&#13;
        try:&#13;
            URL_toget = URL_work_queue.get(block=False)&#13;
        except Queue.Empty:&#13;
            print "thread exiting, id: " + str(thread_id)&#13;
            sys.exit()&#13;
        urllib2.urlopen(URL_toget)&#13;
        print "got URL: " + URL_toget&#13;
&#13;
# fill the queue with work and block until we are done filling the queue&#13;
&#13;
producer_thread = Thread(target=putURL, args=(host_list,))&#13;
producer_thread.start()&#13;
producer_thread.join()&#13;
&#13;
# we can now start consumers&#13;
&#13;
for i in range(number_of_consumer_threads):    &#13;
    t = Thread(target=getURL, args=(i,))&#13;
    t.start()&#13;
    thread_list.append(t)&#13;
&#13;
for thread in thread_list:&#13;
    thread.join()&#13;
</pre>
</td>
<td width="212"></td>
</tr></tbody></table><p>This pattern is efficient and can easily be extended to have multiple sets of threads and queues connecting them. Generally speaking I try to break the work tasks up into computationally intensive pieces (such as parsing a web page for content) and IO intensive tasks (such as requesting a web page or reading or writing a file). This allows tasks that do not require a lot of computation to quickly yield the GIL lock (more on this in the next article) allowing another thread to run (you want to do IO, especially network IO in parallel as much as possible since it is so slow). If we were to download the web page and process it within the same thread for example we would be limiting the number of simultaneous downloads since we’d be processing web pages when we could also be downloading them.</p>
<p>Now as for code quality the above code has a number of significant problems (mostly architecturally but one or two implementation-wise) that will be addressed in the later articles of this series.</p>
<p><strong>Work Queues</strong></p>
<p>As you can see work queues provide an ideal mechanism for linking pools of threads. Implementing queues from scratch in other languages such as C or Java is an incredibly complex task, what if two threads try to write to the queue at the same time, how do you sure that two separate objects are created properly, or if multiple threads are reading from the queue how do you ensure that objects are handed out properly? The good news is that in Python due to its providing low level primitives like threads and queues, and the Global Interpreter Lock (GIL) you really don’t have to care or spend much time making sure you get it right since it’s built in.</p>
<p><strong>Appendix</strong></p>
<p>[THREAD]</p>
<p><span class="amp-wp-inline-61cd676b7bd65a074cc1d867fbbea1de"><a href="http://docs.python.org/library/thread.html">http://docs.python.org/library/thread.html</a></span></p>
<p>[THREADING]</p>
<p><span class="amp-wp-inline-61cd676b7bd65a074cc1d867fbbea1de"><a href="http://docs.python.org/library/threading.html">http://docs.python.org/library/threading.html</a></span></p>
<p>[WORKQUEUE ]</p>
<p><span class="amp-wp-inline-61cd676b7bd65a074cc1d867fbbea1de"><a href="http://docs.python.org/library/queue.html">http://docs.python.org/library/queue.html</a></span></p>
<p>[Producer-consumer problem]</p>
<p><span class="amp-wp-inline-61cd676b7bd65a074cc1d867fbbea1de"><a href="http://en.wikipedia.org/wiki/Producer-consumer_problem">http://en.wikipedia.org/wiki/Producer-consumer_problem</a></span></p>
<div id="_mcePaste" class="amp-wp-inline-2d119d10fc2234fa6e8a2b1b22ff1050"><!--[if gte mso 9]&gt;  Normal 0   false false false        MicrosoftInternetExplorer4  &lt;![endif]--><!--[if gte mso 9]&gt;   &lt;![endif]--> <!--[if gte mso 10]&gt; &lt;!   /* Style Definitions */  table.MsoNormalTable 	{mso-style-name:&quot;Table Normal&quot;; 	mso-tstyle-rowband-size:0; 	mso-tstyle-colband-size:0; 	mso-style-noshow:yes; 	mso-style-parent:&quot;&quot;; 	mso-padding-alt:0in 5.4pt 0in 5.4pt; 	mso-para-margin:0in; 	mso-para-margin-bottom:.0001pt; 	mso-pagination:widow-orphan; 	font-size:10.0pt; 	font-family:&quot;Times New Roman&quot;; 	mso-ansi-language:#0400; 	mso-fareast-language:#0400; 	mso-bidi-language:#0400;} --> <!--[endif]-->
<p class="TableContents">#!/usr/bin/env python</p>
<p class="TableContents">import urllib2</p>
<p class="TableContents">from threading import Thread</p>
<p class="TableContents">hosts = [“<a href="http://lwn.net/&amp;#8221" rel="nofollow">http://lwn.net/&amp;#8221</a>;, “<a href="http://seifried.org/&amp;#8221" rel="nofollow">http://seifried.org/&amp;#8221</a>;, “http://google.com/”%5D</p>
<p class="TableContents">
</p><p class="TableContents">def getURL(URL):</p>
<p class="TableContents">urllib2.urlopen(URL)</p>
<p class="TableContents">print “got URL: ” + URL</p>
<p class="TableContents">
</p><p class="TableContents">for item in hosts:</p>
<p class="TableContents">t = Thread(target=getURL, args=(item,))</p>
<p><span class="amp-wp-inline-5bb1f0538cda713ea03612369398c0e8"> t.start()</span></p>
</div>
</div>
<footer class="amp-wp-article-footer">
<div class="amp-wp-meta amp-wp-tax-category">
Categories: <a href="http://kurt.seifried.org/category/python/" rel="category tag">Python</a> </div>
<div class="amp-wp-meta amp-wp-tax-tag">
Tags: <a href="http://kurt.seifried.org/tag/performance/" rel="tag">performance</a>, <a href="http://kurt.seifried.org/tag/python-2/" rel="tag">python</a> </div>
<div class="amp-wp-meta amp-wp-comments-link">
<a href="http://kurt.seifried.org/2010/05/31/python-performance-part-1/#comments">
Leave a Comment </a>
</div>
</footer>
</article>
<footer class="amp-wp-footer">
<div>
<h2>Kurt Seifried</h2>
<p>
<a href="https://wordpress.com/?ref=footer_blog">Blog at WordPress.com.</a>
</p>
<a href="#top" class="back-to-top">Back to top</a>
</div>
</footer>
<amp-pixel src="https://pixel.wp.com/b.gif?rand=RANDOM&#038;host=kurt.seifried.org&#038;ref=DOCUMENT_REFERRER&#038;amp=1&#038;blog=86342&#038;v=wpcom&#038;tz=-7&#038;user_id=0&#038;post=55&#038;subd=kurtseifried"></amp-pixel>
<amp-pixel src="https://pixel.wp.com/b.gif?rand=RANDOM&#038;v=wpcom-no-pv&#038;crypt=UE40eW5QN0p8M2Y%2FRE1TaVhzUzFMbjdWNHpwZGhTayxPSUFCMGRVYVNrSFguN3FwSmQ5RGtNX3VQcj1yVzhiflM1THQtLGFdQ2toOXYlSTFFR3FyWV8vNWlURCVDWHdySjh8XVMzP1V%2BZlNZQS9uUHRpTSZuOEhqXTVCOUFDRGpkKzhLSWVuTWROVyZydj1UMkFYQS5GR3dMZkkuLlZCN3VZVHpRWU1PNElzektmQ1h3TGIzMWZVVzIlX2hlMVkwaW1oWVF2bk1mTFJ6UG9KRGZjPU03dG5zeENGLUJhbXBSWFE5bzFRdnpE"></amp-pixel>
</body>
</html>
